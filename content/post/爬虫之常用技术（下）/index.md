---
slug: fd2c02cf
author: "昊色居士"
title: "爬虫之常用技术（下）"
description: 
date: 2022-08-07T17:54:36+08:00
image: rand
math: 
license: 
hidden: false
comments: true
draft: false
tags: [
    "爬虫", "Python"
]
categories: [
    "爬虫", "Python"
]
series:  [

]
---

# 爬虫之常用技术（下）

## 网络请求

python 中发起网络请求的库，有很多，比如最常用的`requests`，发起异步请求时最常用的`aiohttp`，还有一起其他的库，这里我推荐的库是：`httpx`，我认为他的优点是：

- 兼备同步请求和异步请求。同时同步的请求和`requests`的使用上是区别不大的
- 在发起异步请求时，使用上是比`aiohttp`简单的
- 支持`http2`。如果要爬取的目标网站使用了`http2`的网络协议，使用`requests`库是爬取不了的
- 在配置代理上面很灵活，可以按照网站、协议的不同分别设置代理。

剩下的具体使用上面大家可以自行的查询资料。很多人写的比我详细多了。

## 加密解密

在爬虫上面是离不开逆向的，然而逆向也同样离不开加密解密，常用的对称加解密、非对称加密同样要了解，了解基本的概念和 python 中常用的写法

### 对称与非对称

这个是啥意思呢，就是能解和不能解的区别。对称就是加密后还能解开，非对称就是正常情况下是解不开的

### md5 加密

md5 是一种非对称解密，也非对称加密中很用的一种。特征就是 32 位或 16 位的`16进制`数字，常作为参数的签名来使用，下面来简单说下 python 的使用方法：

```python
from hashlib import md5

def calc_md5(data_str: str):
    return md5(data_str.encode(encoding='utf-8')).hexdigest()
```

上面是示例代码，目标参数是一个字符串，但在函数里面会转换成字节，然后调用`hashlib`的 md5 方法进行加密。返回值同样也是字节，最后在把字节转换成 16 进制数字

### AES 加密

AES 是一种对称加密，其中还分 CBC、ECB 等多种，他是特点就是有：

- 加密和解密时存在：`key`和`iv`，`key`就是加密是密钥，`iv`就是偏移量
- 以`16个字节`为一组，所以长度要是 16 个字节的倍数，但如果目标数据不是`16个字节`的倍数怎么办，这里就出现了如：PKCS7Padding、PKCS5Padding 等多种填充算法

其中以我遇到的来说常用的就是：`AES+CBC+PKCS7Padding`的组合。由于比较复杂，示例代码后续单独拿出来说。

### BASE64 加解密

base64 严格来说不属于加密，而是一种文字的编码形式，把二进制数据来用 64 个个打印字符来表示，其中会出现使用`=`补位的情况，所以开始很长一串字母加数字组成的字符串，里面还是`=`的，大概率就是 base64 了，但要清楚，不是所有的`base64`都有等号，python 里面使用的方法:

```python
import base64

# 加密
base64.b64encode("hello".encode()).decode()

解密
base64.b64decode('aGVsbG8='.encode()).decode()
```

意思很简单，和`md5`差不多，就是输入参数和输出参数就是字节的，所有需要编码和转码

### 非字符串的显示方式
譬如上面的加解密的输入输出参数和key、iv参数，都是字节类型的，但不是所有的字节类型都能直接转换成字符串的，这里如果想要存储的话，就需要其他的方式转换成可以看懂的字符串。
* 字节与base64的转换
* 字节与16进制的转换

下面在说说16进制的示例代码：
```python
from binascii import b2a_hex, a2b_hex

b2a_hex(b'hello').decode()
'68656c6c6f'

a2b_hex('68656c6c6f')
b'hello'
```
如上所见，就不需要多解释了，就是互相转

## 数据的保存方式
爬下来的数据肯定是要保存的，常用的保存方式要知道，比如：json、xml、excel、csv、关系数据库、非关系数据库等
当就爬虫来说使用关系数据库的很少，也不适合。

### json
json格式，如果是使用自带的库，就要注意时间类型的问题，或者使用`orjson`库来代替自带的库，使用上差不多

### excel、xml、csv等
这几种格式去搜的话都有常见的库的来进行进行创建操作，但`pandas`库也是支持这几种文件的导出，而且方便快捷

### 数据库
数据库使用上使用MongoDB、REDIS等非关系的数据库比较多。具体的先查查资料吧，后面在详细的说说

## 结束了
简单的介绍了爬虫中使用到的一些库，都是在我看来比较实用的，介绍呢也不是很深，更深入的我还是希望大家可以自行的去了解，去学习。在我这呢，更希望大家学到的是方法和那个关键的点，就是搜索一个东西的关键词一样。祝大家学有所成。